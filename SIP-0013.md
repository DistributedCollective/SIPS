### SIP-0013: BI-WEEKLY CONTEST FOR TESTS REPORTS FOR SOVRYN USERS

#### **Introduction:**

Every Time before Sovryn developers push out new features on the production net (so far, the RSK main-net), a test is performed on testnet first.

At this point, Sovryn users have been very helpful in the past and this should be rewarded. In this sense, the users usually help us to improve the user-interface, the experience, and from time to time, they find indeed some bugs.

Regarding the bugs that Sovryn developers have been able to find with the help of users, and then fix them, is one of the reasons to decide a good bounty for users.

Even though the proposal recently approved by the SIP0008, refers only to bugs of another type that have to do with the prevention of losses on funds/treasury, it is advisable encourage users to find any kind of bugs that arise on day-by-day, on the operation of the platform, in any of its aspects. So this document proposes a regular bounty contest as a solution to reward this kind of commitment by the Sovryn user.

#### **Objectives and Propositions:**

This proposal discuss how much should be awarded and how often.

Here is proposed to do a contest at the end of each sprint, asking the users to deliver a report with some specifications, to a jury.

A regular contest makes the deliverance of these kinds of rewards a preset procedure, which will at the most only need one SIP approval.

Regarding the awards, they can be ordered as first, second and third place in a sequence of 1 whole, 1/2 and 1/3 of the main prize value.

The proposed prizes are as follow: a first prize of 120 SOV tokens, a 2nd prize of 60 SOV and third prize of 40 SOV, for a total of 220 SOV tokens each sprint and 440 SOV tokens awarded per month.

#### **Report Specifications:**

Each user must supply _before the last day_ of the sprint a **_written in English_** report of his tests to a jury board.

The report each user prepares to qualify in the contest, must have:

1. The title of the feature tested (e.g.: “**Observations on USDT Integration**”);
2. _**His/her pseudonym**_ under the title in order for the jury to be able to reach/contact this user;
3. An abstract in the first page with no more than 300 words, with the headlines about what the report covers in a very gist way.
4. A small index in the second page indicating the tests covered. Also the index page must indicate the total number of words in the report, **_and the RSK address_** he/she has used to test the feature.
5. A conclusion on the penultimate page, with no more than 400 words, containing very summary headlines about what was discovered or recommended in the report.
6. A table of features to evaluate, as described in the section “Checklist for Report Assessment”.

**Special Requirements:**

- Each transaction performed whether failed or successful must be indicated by the URL of that transaction in a block explorer, explaining what is happening in that transaction.

- The user should associate _at least_ one address for his/her tests report. This is important to verify the user if he/she wins.

- Each test set the user performs, must be described in **special sections**, with a subtitle illustrative of the test, highlighted, and easily visible.

- Each **special section** of tests must indicate the O.S. used and version, the wallet brand and version, and the browser used for tests if apply. If a test suite was used (like Brownie, Truffle, HardHat, and so on), please indicate which package/version.

- Each section should describe step by step the test if it applies, and if there are suggestions around the user interface, there should be screenshots that illustrate the problem found or the improvement suggested.

- Screenshots can be improved indicating the areas to watch with arrows or circles of bright colors, contrasting with the image.

- These reports are expected to be done over features yet to be deployed on mainnet, i.e. only on testnet. If the user thinks there may be an exception, it should be discussed previously with one of the jury, at least.

#### **Juror Duties:**

- The jury for these contests must comprise at least three people. Each jury must read carefully all the reports. If they find a bug, it must be immediately reported in the proper Git Hub repository with the appropriate issue.

- The main objective is functional: the most useful report will be awarded.

- A report that suggests improvements (or at least it verifies that no improvements are needed), or if the report looks into some transactions (e.g. into the data of the explorer) proving that everything is fine, or that certainly something is wrong, it qualifies to the first prize. It is expected to encourage enough people to have 3 winners.

- If there are not enough people, say, one, two or three contestants, even in that case the reported qualities are important to decide if the prizes are awarded. The jury will have the last say in this regard.

- Each two Saturday the jurors must celebrate a meeting to discuss the reports received and discuss about the three best reports.

- A jury with an odd number of jurors guarantees that a decision is always taken.

- The jury must decide the winners within the next week, and approved by the means of a multi-sig transaction, the awarding of the prizes. The decisions will be based on the basis of a checklist of attributes for each report as described in the next section.

#### **The Leaker**

An additional member for the team will be present at least for the first quarter these contests are celebrated. This member, named “The Leaker” will perform the function to evaluate:

- Which reports are or not compliant with the minimum requirements to participate in the contest.

- If a report is repeated, i.e.: it is reporting exactly the same bugs and recommending the same improvements, will be discarded, giving priority to the first of them.

- The Leaker will have the duty to keep updated a spreadsheet with the issues already reported.

- A data to be included in this spreadsheet will be the summarized score for each report, according the checklist filled by each juror.

- The Leaker won't be part of the signatories of the MultiSigWallet, or treasury.

- The Leaker can be any motivated member of the community, and will be chosen by the jury, from among those who express their interest.

- This position will only be a trial for thwe first quarter. If no more than 30 reports are received by contest, the position will be discarded.

#### **Report Requirements:**

The report can be filed in a standard format: a .pdf, .docx. or .md files must be accepted as valid. The user must then, obtain the SHA256 value of the file (The user may ask for help to any jury in this sense). Then the user, using the address indicated as the one linked to his/her report, must execute a simple send transaction in the RSK testnet, including in the field of data the hash value obtained from the file of the report.

For example, a user which file has the following SHA256 hash value:

- 0xc3e24ffb055674ff4c3a053a57386262d25846d988151e887acb48652483d440

Will put in the data field of the wallet at the time of doing the transaction, the sequence of characters:

- c3e24ffb055674ff4c3a053a57386262d25846d988151e887acb48652483d440

The outcome will be similar to this transaction:

- https://explorer.testnet.rsk.co/tx/0xd20a17488e74d7174f6ddc0bb76d54c727002b8d9b09107b7cbd61f416f5f9a8

This practice is expected to prevent any dispute (by that moment or in any future) between users over the ownership of any report, and will give to the jury a proof that the address receiving any award corresponds to the maker of the winning report.

The order in which the reports are confirmed in the blockchain may solve the potential dispute over who was the first on what; then each user without any rush can file the original report into a _#TestReport_ channel the Sovryn Discord server, together with the transaction with the proof of author-rights for the report; and then the jury will evaluate each report deciding for a winners set.

#### **Checklist for Report Assessment:**

At the end of each report the user should leave in blank, a checklist table, as illustrated in the next page (including the wallet address).

The table must be filled by each jury member, with a qualification from 1 to 5.

The guidelines to give the most objective score are shown below in the table.

**User Address:** 0x0123456789abcdef0123456789abcdef0123456789ab

| Bonuses                   | Jury#1 | Jury#2 | Jury#3 | Total |
| :------------------------ | :----: | :----: | :----: | :---: |
| Clarity of the Report     |        |        |        |       |
| Bug Search in UI          |        |        |        |       |
| Bug Search in Contracts   |        |        |        |       |
| Bug Search in Back-End    |        |        |        |       |
| Step-By-Step Instructions |        |        |        |       |
| Improves for UI           |        |        |        |       |
| Improves for Experience   |        |        |        |       |
| Quality of Images         |        |        |        |       |
| Overall Consistency       |        |        |        |       |
| Total                     |        |        |        |       |
|                           |        |        |        |       |

|

#### **_How to Assess:_**

In General the qualification is centered in the numbers 3 and 2.
Scores of 3 are sufficiency, and 2 imply insufficiency.

Scores above 3, like 4 imply an additional improvement in the report by the user, and even when it may imply some subjectiveness, represent a bonus in the knowledge or skills of the user.

The extremes 1 or 5 are for extraordinary cases; 1 for extraordinary negligence, 5 for a guy who really deserves to be hired by the Sovryn team.

_Special cases_: For those items that could not be evaluated because they did not apply to the case of that report or because they have nothing to do with the purpose of that report, they will be evaluated with the score "_1_".

**Clarity of the Report**: The report should meet the requirements above; if the report fails in any of these aspects, the index, the format of titles and subtitles, the qualification is 2. If all the minimum requirements are met, the qualification is 3.  
Scores above 3 indicate an improvement by the side of the user, usually 4. Is it something extraordinary? Then 5... and this guy should be working with Sovryn in the team of the media content!
If in exceptional cases in which no effort at all is observed, and the report is below the quality expected, then score is 1.

**Bug Search in UI**: Score of 3 if this aspect is present and the report exhibits a diligence by the user to find any bugs in the UI. We give a score of 2 if the feature is absent or the due diligence is not complete in the report.
An extraordinary level (4) is awarded if the user bothers to install the front end repo in his/her machine and test the script at that level. We give a score of 5 for guys who deserve to be working with our Front-End leader.

**Bug Search in Contracts**: Same criterion as the bug search for UI. The user must exhibit some knowledge about smart contracts and how to find if the data is Ok at the explorer level.
Extraordinary levels (4) are recognized if the user proves ability with web3, and some needed languages for testing (e.g. truffle). We give a score of 5 for guys who deserve to be included in Sovryn as solidity developer.

**Bug Search in Back-End**: Same criterion as the bug search for contracts. The user must exhibit some knowledge about servers and how to find if everything seems to be Ok at this level. That is the sufficient level of 3. This feature is not needed in all reports to be present.
Extraordinary levels (4) are recognized if the user proves abilities with tools like CURL; these features are hard for the mean user given that the accesses to back-end and due tests are private; if the user did the diligence to contact our team and verify some important aspects, a score of 4 is granted. A score of 5 is for guys who deserve to be working in our team.

**Step-By-Step Instructions**: A didactical and satisfactory description deserves a 3. If a minimum step by step is not complete, the score is 2.
A score of 4 implies very good communication skills. A level of 5 implies that this guy may be working with Sovryn content.

**Improves for UI**: An understandable explanation of how the user would like to see our interface, deserve a satisfactory score of 3. If this minimum is not met, then it is 2.
Users showing additional skills in design deserve a 4. Should the guy have an interview with our creative team? Then the score must be of 5.

**Improves for Experience**: Not only appearance of the UI, but the quality of the experience of the user should be evaluated. If the feature is present, and sufficiently explained, then the score is 3. If absent, incomplete or not understandable, then the score is 2.
If the user shows additional skills as front end designer, video and image content, then the score should be 4.

**Quality of Images**: If the images are enough to be understood, the score is 3. If there is a lack of resolution or the reader gets hard to understand what is shown, then the score is 2.
Users that exhibit good skills with images and effects deserve a 4. Does this guy deserve to be working in the team of special effects? Then give him a 5.

**Overall Consistency**: Let’s check the report as a whole. Is it consistent? Is it complete? Are the language and the way to describe things, precise and well developed?
The sufficiency in these questions deserves a score of 3.
If the user showed a “journalist” level report, then the score should be 4. Scores of 5 implies the guy deserves an interview with the adoption team.

Certainly all these scores will have a degree of subjectiveness, but the point in organizing a jury of at least 3, is expected to give the report a sufficient level of objectiveness.

#### **Periodical Meetings to Re-Adjust Parameters:**

Once per month the jury members could have a meeting or a forum discussion to propose an adjustment of any of these parameters, including the awards, discussions about the budget, etc.

As SOV token increases its value, the awards should be fixed to the new values.

#### **Budget Proposal**:

1. A Multi-Signature contract of 3-5 must be deployed for the treasury of the contests events.
2. Three of the addresses registered in the contract will correspond to the jury. The other two will correspond to two members of the Sovryn treasury.
3. The treasury of the contests will be held in SOV tokens.
4. The amount of tokens to be granted as awards will totalize 440 SOV per month.
5. Each jury will be rewarded with 110 SOV tokens each month. This means a total of 330 SOV tokens per month to pay the jurors. The Leaker will receive 70 SOV per month.
6. In the first day of each month the treasury of Sovryn platform will transfer to the treasury of the contests events (the Multi-Signature contract), a total of 840 SOV tokens and at least 30,000 satoshis to any of the juror members to distribute it among the jury in order to pay gas fees.
7. This project as contest series may be disincorporated at the end of each quarter by a SIP proposal. This first proposal grants a first period for the contest system of three months. If there is no successful SIP counterproposal at the end of this period, to disincorporate this reward system, it may be extended indefinitely.
8. New jury members can be added, by the approval of pre-existent members, by adding the user in the Multi-Signature contract.
9. A member can be disincorporated by a quorum, with a transaction in the Multi-Signature contract.
10. The addresses to be incorporated to the Multi-Signature contract will be:

- 0x0000000000000000000000000000000000000001
- 0x0000000000000000000000000000000000000002
- 0x0000000000000000000000000000000000000003
- 0x0000000000000000000000000000000000000004
- 0x0000000000000000000000000000000000000005

11. The address of the Multi-Sig contract (the treasury of the contest events) is:

- 0x0000000000000000000000000000000000000006

#### **Comments and Observations**:

Please make a reference about this SIP-0013 in the channels of #user-feedback or #bounties in our [Discord Server](https://discord.gg/VPpd5crF)

As members of Sovryn family the possibility of collusion between the jury members is really low, however, in order to make it safer, the inclusion of at least two members of the Sovryn treasury is a reasonable measure. Just in the case of a lack of agreement, the signatures of these treasurers will be required.

#### **Proof of Concept For The Multi-Sig Contract**

A proof of concept to demonstrate the feasibility of the Multi-Signature contract as treasury for this proposal is described as follow:

1. The contract [MultiSigWallet](https://github.com/DistributedCollective/Sovryn-smart-contracts/blob/development/contracts/multisig/MultiSigWallet.sol) was deployed in Ropsten network, and [verified,](https://ropsten.etherscan.io/address/0x698d626c0f83afc1d21b373d20f0b188cd706679#code) with three addresses and a minimum for the approval of transactions of two users.
2. An ERC20 token contract called [ACRES](https://ropsten.etherscan.io/address/0x92bba00069e2cab3cea7116238e4ebec223b6e87#code) was selected in this network to this proof of concept.
3. A `mint` of ACRES tokens [was performed](https://ropsten.etherscan.io/tx/0xac7b39c185b63eea4b7e9983228f664c6e0b43c7bbf5f28146f906b88e97f6d0) in favor of the MultiSigWallet contract, for the amount of 890 ACRES.
4. A `submitTransaction` from the MultiSigWallet [was performed](https://ropsten.etherscan.io/tx/0x148a39ab365f5f4e294a03eaac0676c2acecf6a6b035f274a39af86d066aac4a) by one of the MultiSigWallet users, in which it is proposed the transfer of 120 ACRES to the user `0x6e7B40556FD4Fc174Cf02d17FCF96871A9646ca6`. This way the transaction number "0" was created in the MultiSigWallet.
5. Another user [called](https://ropsten.etherscan.io/tx/0x44eeb25ff0f24a01a3f5d17b75ff88cd77ecc886fa1176ca7cc52fbf9ecb3378) the function `confirmTransaction` to the MultiSigWallet, for the transaction number "0".
6. Lastly [here](https://ropsten.etherscan.io/token/0x92bba00069e2cab3cea7116238e4ebec223b6e87?a=0x6e7b40556fd4fc174cf02d17fcf96871a9646ca6) we can verify that the user `0x6e7B40556FD4Fc174Cf02d17FCF96871A9646ca6` received successfully their 120 ACRES tokens.
7. Repeating this process all the prizes can be awarded and the incentives for jury can be paid
